---
title: 'Water Resources in Copenhagen during 20th century'
author: "Adela Sobotkova"
date: "March-2021 updated`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
---

```{r setup, include=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
	             cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
```

This script visualizes the spatial component of the data accompanying the Spring 2021 course on the City: Between Culture and Nature, taught by Mikkel Thelle and Mikkel Høghøj. 
The course surveys the gradual appearance of private and public bathing facilities, toilets and communal hygienic resources in the city of Copenhagen during the 20th century.
By editing elements in this script, you can explore different aspects of past and present hygienic amenities in the capital of Denmark.  

# Before we start: data wrangling
First load the packages necessary for spatial data visualisation and analysis.
```{r libraries}
library(sf)
library(tidyverse)
library(spatstat)
library(spatialkernel)
library(googlesheets4)
library(leaflet)
```

## Spatial data
Next, load your spatial data - polygons representing the suburbs of Copenhagen. 
```{r}
suburbs <- st_read("data/bydel.shp", options = "ENCODING=WINDOWS-1252") # thank you, Malte, for the options argument which fixed the Danish chars

plot(suburbs$geometry)
tail(suburbs)
#write_rds(suburbs, "data/CPHsuburbs.rds")

suburbs$id

```
## Attribute data
Next let's bring in the attribute data. 
I read the data from a google sheet where my colleagues and I can edit it. You can load it from there if you have a `googlesheets4` package installed, or you can use the `read_csv()` function to read the `wc.csv` provided in the data folder
```{r read-wc}
# Uncomment the lines below to read data from GDrive
# wc <- read_sheet("https://docs.google.com/spreadsheets/d/1iFvycp6M6bF8GBkGjA2Yde2yCIhiy5_slAkGF-RUF7w/edit#gid=0",
#                     col_types = "cnnnnnnnn")
# write_csv(wc, "data/wc.csv")
wc <- read_csv("data/wc.csv")
wc
```
## Spatial resolution adjustment - data aggregation
Data on access to hygienic facilities and other water resources in Copenhagen now looks good and tidy, but its *spatial resolution* is higher than the provided polygons (as in we have multiple rows that all fit within one suburb `id`). We therefore use the `group_by()` function to aggregate the data by id before we continue with any spatial operations.  Given that the dataset is in fact a time-series, and each `kvarter` has a record for a given year or decade, we need to group first by the `year` and then only by `id`. 

While aggregating the finer scale data into larger units, it is convenient to generate some statistics, such as percentages of flats that have bath and wc and hot water access within each suburb. We do this using the `summarize()` function below.
```{r}
wcdata <- wc %>% 
  group_by(year, suburb_id) %>% 
  summarize(flats = sum(flats),
            bath = sum(bath),
            pct_bath = bath/flats*100,
            wc_access=sum(wc_access),
            pct_wc= wc_access/flats*100,
            warmH20=sum(hot_water),
            pct_wH20=warmH20/flats*100,
            communal_wc = sum(wc_communal_ct),
            communal_bath = sum(bath_communal_ct))
wcdata  
#write_rds(wcdata, "data/CPH_wcdata.rds")
```

## Join the aggregated attribute data with its spatial representations
Now we can join the data with the spatial polygons
```{r merge data}
wc_spatial <- suburbs %>% 
  merge(wcdata, by.x= "id",by.y ="suburb_id")
wc_spatial
```
Now that we have a merged spatial dataset with attributes, let's review what attributes are available for visualisation
```{r check names}
#Review the column names to see what new columns you have created
names(wc_spatial)
```
There is the suburb polygon data, such as id, bydel_nr, navn and areal_m2, and there is also the attribute data such as year, flats, bath ,etc.
This gives us lots of choices for display. Lets put the data in a map.

# Plot the data on the map

Let's start by plotting one year alone, to learn how the map works.

## Flats and water resources in 1950
Run the whole chunk below, and once it renders, look at the map. Afterwards, try changing the definition of what is to be displayed on line 116. For example, replace `"flats"` for some other column, such as `"pct_bath"`, or `"wc_access"` to see how the map changes. 
To modify the legend, you can modify line 118 where we describe `style`. Replace `style = "jenks"` with `"pretty"`, or `"equal"`, or `"quantile"`. What happens to your classification?

```{r plot1950}
wc1950 <- wc_spatial %>% 
  filter(year==1950)

library(tmap)
tmap_mode(mode = "plot")
tm_shape(wc1950) +
  tm_borders(col = "black",
             lwd = 1) +
  tm_polygons("flats",
              id = "navn",
             style = "jenks")+
  tm_legend(legend.position= c("RIGHT", "TOP"))+
  tm_compass(position = c("RIGHT", "BOTTOM"),
             type = "rose", 
             size = 2) +
  tm_scale_bar(position = c("RIGHT", "BOTTOM"),
               breaks = c(0, 2, 4),
               text.size = 1) +
  tm_credits(position = c("RIGHT", "BOTTOM"),
             text = "Adela Sobotkova, 2021") +
  tm_layout(main.title = "Copenhagen 1950 situation",
            legend.outside = FALSE)
```

## Flats through time
Now, that you have mastered visualization of a single year, let's plot all the years we have available!
```{r view-flats, fig.width = 12}
tmap_options(limits = c(facets.view = 5)) # we want to view 5 periods
tmap_mode(mode = "view" )
tm_shape(wc_spatial) +
  tm_facets(by = "year",
            ncol=3, nrow = 2)+
  tm_polygons("flats",
              id = "navn",
             style = "jenks")+
  tm_layout(main.title = "Copenhagen Flats",
            legend.outside = TRUE)
```
<br>
## Lets look at flats per square kilometer
Now that we have a spatial object, we can create new columns, for example utilizing the shape area to calculate the density of flats per sq km.
```{r addsqkm}
wc_spatial <- wc_spatial %>% 
  mutate(area_km2 = areal_m2/1000000,
         flat_per_km = flats/area_km2)
```

```{r viewflats-per-km, fig.width = 12, fig.height = 12}
library(tmap)
tmap_options(limits = c(facets.view = 5)) # we want to view 6 years
tmap_mode(mode = "view" )
tm_shape(wc_spatial) +
  tm_facets(by = "year",
            ncol=3, nrow = 2)+
  tm_polygons("flat_per_km",
              n=5,
             style = "jenks") #+
  
```

<br>
## Access to toilets and baths, per suburb and sq kilometer

Lets calculate the baths and toilets available per square kilometer per each suburb
```{r view-pct-bath, fig.width = 12}
library(tmap)
tmap_options(limits = c(facets.view = 5)) # we want to view 5 years
tmap_mode(mode = "view" )
tm_shape(wc_spatial) +
  tm_facets(by = "year",
            ncol=3, nrow = 2)+
  tm_polygons("pct_bath",
              id = "navn",
             style = "pretty", 
             title = "% of flats with <br> access to bath") #+
  
```
<br>
<br>
```{r view-pct-wc, fig.width = 12}
library(tmap)
tmap_options(limits = c(facets.view = 5)) # we want to view 5 periods
tmap_mode(mode = "view" )
tm_shape(wc_spatial) +
  tm_facets(by = "year",
            ncol=3, nrow = 2)+
  tm_polygons("pct_wc",
              id = "navn",
             style = "pretty", 
             title = "% of flats with <br>access to WC")
  
```

<br>
## You can further recalculate the number of baths per sq kilometer

```{r bath-per-km}
wc_spatial <- wc_spatial %>% 
  mutate(bath_per_km = bath/area_km2,
         wc_per_km = wc_access/area_km2)

```

### ..or continue with communal resources and warm water
Why not practice and try plotting the flats that have access to communal baths and wc, and or hot water? Create your own map here, following the examples above.

```{r}

```

<p>


# Access OSM data for Copenhagen and retrieve (whatever would be relevant?)

The [OpenStreetMap](https://wiki.openstreetmap.org/wiki/Map_features) contains free and open spatial data for physical features on the ground, with each features' type being define using [key:value pair tags](https://wiki.openstreetmap.org/wiki/Map_features).  Each tag describes a geographic attribute of the feature being shown by that specific node, way or relation. 

Use:

* `osmdata:opq()` to define the bounding box of the osm request
* `osmdata:add_osm_feature()` to define the key:value pairs you are looking for
* `osmdata:osmdata_sf()` to retrieve the osm data.

```{r extract-osm-data}
library(osmdata)

# Create a bounding box
bb  <- suburbs %>% st_transform(4326) %>% st_bbox()
plot(bb)
q <- opq(bbox = bb,timeout = 180)
qa  <- add_osm_feature(q, key = 'amenity',value = 'public_bath')
#qb     <- add_osm_feature(q, key = 'amenity',value = 'drinking_water')
qc     <- add_osm_feature(q, key = 'amenity',value = 'shower')
qd     <- add_osm_feature(q, key = 'amenity',value = 'toilets')
#qe     <- add_osm_feature(q, key = 'amenity',value = 'water_point')
public_bath <- c(osmdata_sf(qa),
                 osmdata_sf(qc),
                 osmdata_sf(qd))
```

## Clean up OSM data
Use the following code to clean the results and project them in Danish UTM.

This code:

* removes the duplicated geometries thanks to `osmdata::unique_osmdata` (see the documentation for details)
* projects into WGC84 UTM32
* keeps the name attribute only
* computes the centroids for the baths stored as polygons
* Eventually, the baths outside our CPH suburbs are removed.
```{r osm-wrangle}
library(osmdata)
bath_uniq <- unique_osmdata(public_bath)

rpoint <- bath_uniq$osm_points %>% 
  filter(!is.na(amenity)) %>% 
  st_transform(32632) %>%
  dplyr::select(name) 

rpoly  <- bath_uniq$osm_polygons %>% 
  st_transform(32632) %>% 
  dplyr::select(name)  %>% st_centroid()

baths_osm <- rbind(rpoly,rpoint)   

baths_osm <- st_intersection(baths_osm, st_transform(suburbs, 32632) %>% st_geometry() %>% st_union())

# transform also historical baths 
baths_cph <- wc_spatial%>% 
  st_centroid() %>% 
  st_transform(32632) %>% 
  mutate(radius = sqrt(bath_per_km)) %>% 
  arrange(desc(bath_per_km))
```

## Display two maps side-by-side
Now, let's display the results in two synchronized `mapview` maps:

* one with bathing resources in suburbs
* another one with baths extracted from OSM.
* Use the `mapview::sync` function to display both maps side by side with synchronisation.

```{r mapview-sync}
library(mapview)
# library(leafsync)
# library(leaflet)
map_osm <-  mapview(baths_osm, map.types = "OpenStreetMap", 
        col.regions = "#940000", 
        label = as.character(suburbs$name), 
        color = "white", legend = FALSE, layer.name = "Baths in OSM",
        homebutton = FALSE, lwd = 0.5) 


#test map
mapview(baths_cph[,-3], map.types = "Stamen.TonerLite", cex="radius", legend=FALSE, col.regions="#217844", lwd=0, alpha=0.4)

map_cph <-  mapview(baths_cph[,-3], 
          map.types = "OpenStreetMap", 
        col.regions = "#940000", 
        color = "white", 
        cex = "bath_per_km",
        legend = TRUE, 
        layer.name = "Baths per sq km <br>in suburbs from 1970",
        homebutton = FALSE, lwd = 0.5) 


sync(map_osm,map_cph)

```
What a fantastic synced map! Two maps with entirely different datasets and moving interactively. The synced map functionality is nice, but the comparison does not make much sense: OSM public bathrooms versus private bathing facilities originating from suburb polygons are not exactly comparable. How can we improve?


## Improve the display with some comparable dataset
It might be better to combine the OSM data with the public bathhouse data that we had looked at previously in Leaflet.

We need to 

* load the data from googlespreadsheet
* filter out missing coordinates and convert to sf object
* project to WGS84 UTM 32

```{r get-hist-baths}
# baths <- read_sheet("https://docs.google.com/spreadsheets/d/15i17dqdsRYv6tdboZIlxTmhdcaN-JtgySMXIXwb5WfE/edit#gid=0",
#                     col_types = "ccnnncnnnc")
# write_rds(baths,"data/baths.rds")
baths <- read_rds("data/baths.rds")
names(baths)

hist_bathhouses <- baths %>% 
  dplyr::select(BathhouseName,Longitude,Latitude,Quality) %>% 
  filter(!is.na(Longitude)) %>% 
  st_as_sf(coords=c("Longitude", "Latitude"), crs = 4326)

hist_baths <- st_transform(hist_bathhouses, crs=32632)

#test map
library(mapview)
mapview(hist_baths, map.types = "Stamen.TonerLite",
        #cex="radius", legend=FALSE,
        col.regions="#217844", lwd=0, alpha=0.4)
```

Now, let's load this projected historical bathouse object in the synced map so we can compare the locations with OSM data.
```{r}
library(mapview)
map_osm <-  mapview(baths_osm, map.types = "OpenStreetMap", 
        col.regions = "#940000", 
        label = as.character(suburbs$name), 
        color = "white", legend = FALSE, layer.name = "Baths in OSM",
        homebutton = FALSE, lwd = 0.5) 

map_hist <-  mapview(hist_baths, 
          map.types = "OpenStreetMap", 
        col.regions = "#940000", 
        color = "white", 
       # cex = "bath_per_km",
        legend = TRUE, 
        layer.name = "Public bathhouses, early 20th century",
        homebutton = FALSE, lwd = 0.5) 

sync(map_osm,map_hist)
```
<br>
Lovely two different patterns, showing current public baths and toilets in Copenhagen and historical ones. The city has grown (how much?) and so clearly have the hygienic facilities. In the next section, you can see how we may formally evaluate the similarity of spatial patterning between the historical and current data.
<br>


# Comparing two point patterns. How do we best do it? 

We have two patterns, historical and OSM data. Are they similar or dissimilar? How do the patterns of historical and current public bathhouses compare beyond a quick eyeball evaluation?

Here we might be able to use some statistical functions that contrast nearest neighbor distances or multi-distance clustering across the two groups.

We should first check the nature of data:  do both patterns represent  *completely mapped data* rather than *sampled data* (where the nature of sampling can affect the comparison)? If the former, one could use nearest neighbor, K-function or Monte Carlo reassignment.

For a tutorial on Kcross function, see Manny G's contribution to this exchange https://gis.stackexchange.com/questions/4484/comparing-two-spatial-point-patterns#4490

## Before we try some cross-functions, we need to wrangle 
But first we need to recast the baths as `ppp` object.
Note: st_union did not work as expected (it is multiplying the features), and so I did a workaround and combined the baths sf objects. En route I found nd this neat post on unioning using Danish municipalities https://gis.stackexchange.com/questions/278818/fastest-way-to-union-a-set-of-polygons-in-r

```{r spatstat}
library(spatstat)

# Prepare the ppp object

# Rebuild ppp from scratch via a combined sf object
st_coordinates(hist_baths)  # 21 coordinates
st_coordinates(baths_osm)   # 166 coordinates
combined <- data.frame(rbind(st_coordinates(hist_baths),
                  st_coordinates(baths_osm)))

# Now I am ssigning marks which need to be a factor
combined$name <- factor(c(rep("H",21), rep("O", 166))) 

combined
# Create an sf object out of the dataframe
b_c <- st_as_sf(combined, coords = c("X","Y"), crs = 32632)

# Convert into a marked ppp and confirm by plotting
b_ppp <- as.ppp(b_c)
b_ppp
plot(split(b_ppp))
```
## Nearest Neighbour Cross Function and Simulation
We randomly reassign marks (H, O) within the combined point dataset and then calculate nearest neighbor between the randomly replaced marked points. Run the simulation 999 times

```{r nn-sim}
nn.sim  <-  vector() #create container for simulation data
P.r <-  b_ppp
for(i in 1:999){
  marks(P.r)  <-  sample(b_ppp$marks)  # Reassign labels at random, point locations don't change
  nn.sim[i]  <-  mean(nncross(split(P.r)$O,split(P.r)$H)$dist)
}
```
### Compare NN - simulation results visually
```{r nn-hist}
hist(nn.sim,breaks=30)
abline(v=mean(nncross(split(b_ppp)$O,split(b_ppp)$H)$dist),col="red")
```

## Ripley-K cross function

Maybe we should look at the multi-scale approach to the bathhouses.
Check out J.Levente's  Ripley K'cross-function [blog](http://blog.jlevente.com/understanding-the-cross-k-function/) and [tutorial](https://github.com/jlevente/publications/tree/master/cross-k). 

```{r kcross}
# Set intervals for moving window (you don't have to)
rc <- seq(0, 3000, 100)

# Run the Kcross function
kcross <- Kcross(b_ppp, i="H",j="O", 
                 # r=rc,
                 correction='none') 
plot(kcross)
```
How to explain this chart? It seems that the OSM baths cluster around historical baths, or are attracted to them even at distances. Or in other words, the 'O' events are closer to 'H' events than we would expect under complete spatial randomness. 
Look at this chart for explanation https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-statistics/multi-distance-spatial-cluster-analysis.htm 

How do we test for statistical significance? The question here is whether the H and O events are similarly clustered or not? Statistical difference can be tested with MC simulation with random labelling of points as O or H type (keeping original ratios) and computing the same cross K-function. The simulation mean and the established simulation envelopes tell us whether the observed *between-type* pattern is statistically significant or not.
```{r simulate-kross-env}
kmult <- envelope(b_ppp, fun=Kcross,
                  nsim=100, i="H", j="O",
                  #r=rc, 
                  correction='none',
                  simulate=expression(rlabel(b_ppp)))  # are the two patterns similarly clustered or dispersed at different scales

plot(kmult, main="Cross-K function")

```
An observed curve within the confidence envelopes means that no matter how we group the points into categories, the pattern we identified in the previous step (by checking on the observed and theoretical values) doesn’t change when randomly assigning events into categories. Here the curve falls outside of the confidence envelopes, meaning that there are differences between the point categories.
